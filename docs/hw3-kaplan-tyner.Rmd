---
title: "Kaggle Digit Recognizing"
author: "Andee Kaplan and Samantha Tyner"
date: "March 4, 2015"
output: 
  pdf_document:
    fig_width: 4
    fig_height: 3
---

Data Pre-Processing and Description
----
The data we are using was heavily pre-processed by MNIST.  Each image was originally in black and white, and was first normalized to fit in a $20 \times 20$ pixel box.  The normalization process, however, created a gray scale.  Subsequently, each image was centered in $28 \times 28$ pixel field around each individual image's center pixel mass. Then, the value of each of the $28 \times 28 = 784$ pixels was recorded.  These values range from 0 to 255, with 0 being the lightest possible and 255 being the darkest possible pixel value. We received the training data in a $42000 \times 785$ data frame.  The first column is the value of the digit drawn, and the remaining columns are the pixel values for each of the 784 pixels.  These columns are labeled "pixel0" through "pixel783."  "pixel0" corresponds to the top left pixel, "pixel27" corresponds to the top right pixel, "pixel756" corresponds to the bottom left pixel, and "pixel783" corresponds to the bottom right pixel in the image.  Below, we plot an example of each digit to give an idea of what the images look like.

```{r readingdata,echo=FALSE,cache=TRUE}
train <- read.csv("~/Desktop/503/HW3/kaggle-digitrecognizer/data/train.csv")
```

```{r exampleplots,message=FALSE,echo=FALSE}
library(plyr)
library(dplyr)
library(tidyr)
library(ggplot2)
idx <- rep(0,10)
for (i in 0:9){
  idx[i+1] <- which(train$label == i)[1]
}
g <- train[idx,]
g2 <- gather(g,label)
names(g2) <- c("digit","pixel","value")
g3 <- g2 %>% group_by(digit) %>% arrange(digit)
examples <- data.frame(x=rep(rep(1:28, 28),10), y=rep(rep(1:28, rep(28, 28)),10), g3)

qplot(x, -y, data=examples, fill=value, geom="tile") + theme_bw() + theme(aspect.ratio=1,legend.position='none') + scale_fill_continuous(low='white',high='black') + facet_wrap(~digit,nrow=2)
```

Pre-Processing
---
To test our models, we separated the 42,000 row training data from Kaggle into a training and a validation set. We used tidyr to randomly sample a third of the observations, making sure to sample the digits representatively.  We use this 13,998 row sample to test all of our models, and our final model has lowest error on this set.  

Feature Selection
---
We wrestled with many different features for this classification problem. We started by deciding to limit our features to counts of non-zero entries instead of mean entry value because the fact that there is any writing in the pixel at all is more important than how dark that writing is. The following plot demonstrates this idea, as all number are still distinguishable when the writing is interpreted as 0 or 1 instead of on a scale from 0 to 255.

```{r plot2, echo = FALSE}
examples$value2 <- as.numeric(examples$value > 0)
qplot(x, -y, data=examples, fill=value2, geom="tile") + theme_bw() + theme(aspect.ratio=1,legend.position='none') + scale_fill_continuous(low='white',high='black') + facet_wrap(~digit,nrow=2)
```

Our general approach to feature selection was to pick features that would capture what we as humans think are most different about the 10 digits.  For instance, there should be a lot of empty space in the middle of the $28 \times 28$ pixel image if the digit drawn in a zero, but not if the digit is an 8 or a 2. With this in mind, we created several features that capture the middle of the image: $2 \times 2$, $4 \times 4$, $8 \times 8$, and $16 \times 16$ squares right in the middle of each image.  The corresponding features are the number of non-zero entries in each of those squares. We also created features for the 4 corners of the image in $8 \times 8$ pixel squares.  Again, we counted the number of non-zero entries in each of those 4 squares to create 4 new features. We also looked at non-zero counts in each row and column of the images, creating 48 more features.  We did not include the $1^{st}$, $2^{nd}$, $27^{th}$ and $28^th$ rows or columns because these entries were all zero for all images in our training set. 

Notes:
talk bout all the ones we tried
talk about the ones we went with and why + plots of them

Model Selection 
---

Notes:
List of all the models we tried 
why we tried and picked each 
error % for all

Results
---

Notes:
results from top 2 (confusion matrices)


Final Model
---

Notes:
Kaggle submission name
final model used
rank in kaggle
final percent error and confusion matrix
